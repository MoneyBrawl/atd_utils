{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "99d57421-e8e8-4f21-a5c0-66861a1ca110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a6f2180e-ff06-480a-8eb5-009e29825fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get the HTML content of a given URL\n",
    "def get_html_content(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3f5d9c5b-cd9c-4fc9-8179-fa7efb016708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_on_dash(df, col):\n",
    "    split_cols = df[col].str.split(' - ', expand = True)\n",
    "    col_prefix, fields = col.lower().split(':')\n",
    "    fields_list = [col.strip().replace(' ', '_') for col in fields.split('-')]\n",
    "    new_col_names = [f\"{col_prefix}_{field}\" for field in fields_list]\n",
    "    split_cols.columns = new_col_names\n",
    "    return split_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3fe83b80-d403-48c0-9d00-2fab3f3bafda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to scrape the team statistics for a particular year\n",
    "def scrape_team_statistics(soup, year):\n",
    "    table = soup.find(\"table\", {\"class\": \"team-statistics\"})\n",
    "    \n",
    "    # Extract the header and data from the table\n",
    "    data = pd.read_html(table.prettify(), flavor='bs4')[0]\n",
    "    df = data.set_index(data.columns[0]).transpose()\n",
    "\n",
    "    split_cols = [col for col in df.columns if ' - ' in col]\n",
    "    \n",
    "    for col in split_cols:\n",
    "        df_col = split_on_dash(df, col)\n",
    "        df[df_col.columns] = df_col\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    df.columns = [x.lower().replace(\":\", \"\").replace(\" / \", \"per\").replace(\" \", \"_\").replace(\"/\", \"_per_\").replace(\"%\", \"perc\").replace(\"3rd\", \"third\").replace(\"4th\", \"fourth\").replace(\"2-\", \"two_\") for x in df.columns]\n",
    "    team_df = df[df.index.str.lower() != 'opponents'].copy().reset_index().rename(columns={'index': 'team_name'}).set_index(pd.Index([year]))\n",
    "    opponents_df = df[df.index.str.lower() == 'opponents'].copy().set_index(pd.Index([year]))\n",
    "    opponents_df.columns = ['opponent_' + col for col in opponents_df.columns]\n",
    "    df = pd.concat([team_df, opponents_df], axis = 1).reset_index().rename(columns={'index': 'year'})\n",
    "    df = df.apply(lambda x: None if x.item() == '-' else x)\n",
    "    pct_cols = df.apply(lambda x: x.astype(str).str.contains('%')).any()\n",
    "    df[pct_cols[pct_cols == True].index] = df[pct_cols[pct_cols == True].index].apply(lambda x: x.str.replace('%', '').astype(float) / 100)\n",
    "    cols_to_convert = [col for col in df.columns if col not in ['year', 'team_name'] + pct_cols[pct_cols == True].index.tolist() and 'time' not in col]\n",
    "    df[cols_to_convert] = df[cols_to_convert].apply(lambda x: x.str.replace(',', '').astype(float))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a850e957-1dee-4459-aa54-b16224520b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_years(team_id):\n",
    "    url = f\"http://cfbstats.com/2022/team/{team_id}/index.html\"\n",
    "    html_content = get_html_content(url)\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    years = soup.find('div', {'id':'seasons'})\n",
    "    return sorted([int(x.text) for x in years.find_all('li')])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d77ee4b5-924e-4196-ba47-c0f64d2abf9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_teams_dict():\n",
    "    with open('cfb_team_ids.json', 'r') as f:\n",
    "        teams_dict = json.loads(f.read())\n",
    "    return teams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "09146a7e-3d6d-42d2-865e-c082f289a5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scrape the team statistics for each desired year\n",
    "dataframes = []\n",
    "teams_dict = get_teams_dict()\n",
    "i = 0\n",
    "for team_name, team_id in tqdm(teams_dict.items()):\n",
    "    print(team_name, team_id)\n",
    "    years = get_years(team_id)\n",
    "    print(years)\n",
    "    for year in years:\n",
    "        url = f\"http://cfbstats.com/{year}/team/{team_id}/index.html\"\n",
    "        if year == years[0] or year == years[-1]:\n",
    "            print(f\"{team_name}\\t{year}\\t{url}\")\n",
    "        html_content = get_html_content(url)\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        df = scrape_team_statistics(soup, year)\n",
    "        dataframes.append(df)\n",
    "    if i % 5 ==0:\n",
    "        pd.concat(dataframes, ignore_index=True).to_csv('cfb_stats_team_statistics.csv', index=False)\n",
    "    i += 1\n",
    "# Combine the dataframes\n",
    "pd.concat(dataframes, ignore_index=True).to_csv('cfb_stats_team_statistics.csv', index=False)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6106ef05-cb95-42a5-8d8e-2f22b7bfebb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = \"http://cfbstats.com\"\n",
    "# html_content = get_html_content(url)\n",
    "# soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "regex = r'team\\/([0-9]+)\\/index'\n",
    "results = [(s.text, re.search(regex, s['href'])) for s in soup.find_all('a', href=True)] # apply regex to each string\n",
    "# valid_results = {r[0]:r[1].group(1) for r in results if r[1] is not None}\n",
    "# with open('cfb_team_ids.json', 'w') as f:\n",
    "#     f.write(json.dumps(valid_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "9e2ad0fd-e748-4d8d-9f9c-0256e6bece67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to scrape the team schedule for a particular year\n",
    "def scrape_team_schedule(soup, year):\n",
    "    table = soup.find(\"table\", {\"class\": \"team-schedule\"})\n",
    "\n",
    "    # Extract the header and data from the table\n",
    "    df = pd.read_html(table.prettify(), flavor=\"bs4\")[0]\n",
    "    if df.shape[0] == 1:\n",
    "        return_cols = ['date', 'opponent', 'attendance', 'home_away', 'win_lose',\n",
    "       'points_scored', 'opponent_points_scored', 'game_duration', 'year',\n",
    "       'team_name']\n",
    "        df[return_cols] = None\n",
    "        return df[return_cols]\n",
    "    df = df[df.Date.str[0] != \"@\"]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%m/%d/%y\")\n",
    "    df[\"home_away\"] = \"home\"\n",
    "    df.loc[df[\"home_away\"].str.contains(\"@\"), \"home_away\"] = \"away\"\n",
    "    df.loc[df[\"home_away\"].str.contains(\"\\+\"), \"home_away\"] = \"neutral_site\"\n",
    "    df[\"Opponent\"] = (\n",
    "        df[\"Opponent\"].str.replace(\"@\", \"\").replace(\"+\", \"\").apply(lambda x: x.strip())\n",
    "    )\n",
    "\n",
    "    split_results = df[\"Result\"].str.split(\" \", expand=True)\n",
    "    df[\"win_lose\"] = split_results.iloc[:, 0].apply(lambda x: x.strip())\n",
    "\n",
    "    split_score = split_results.loc[:, 1].str.split(\"-\", expand=True)\n",
    "    df[\"points_scored\"] = split_score.iloc[:, 0].astype(int)\n",
    "    df[\"opponent_points_scored\"] = split_score.iloc[:, 1].astype(int)\n",
    "\n",
    "    df[\"Game Time\"] = df[\"Game Time\"].apply(\n",
    "        lambda x: datetime.strptime(x, \"%H:%M\").time()\n",
    "    )\n",
    "    df['game_duration'] = df[\"Game Time\"]\n",
    "    df[\"game_duration_seconds\"] = df['game_duration'].apply(lambda x: x.hour*3600 + x.minute*60)\n",
    "\n",
    "    df.drop(\"Result\", axis=1, inplace=True)\n",
    "    df.drop(\"Game Time\", axis=1, inplace=True)\n",
    "\n",
    "    df[\"year\"] = year\n",
    "    team_name = soup.find(\"th\", {\"scope\": \"col\", \"class\": \"team-stat\"})\n",
    "    df[\"team_name\"] = team_name.text\n",
    "    df.columns = [x.lower().replace(\" \", \"_\") for x in df.columns.tolist()]\n",
    "    df['attendance'] = df['attendance'].astype(int)\n",
    "    df['game_duration_seconds'] = df['game_duration_seconds'].astype(int)\n",
    "    df['team_name'] = df['team_name'].astype(str)\n",
    "    df['home_away'] = df['home_away'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e9b694f3-5137-4510-ac55-dec2a053d872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to scrape the team statistics for a particular year\n",
    "def scrape_team_roster(soup, year, team_id):\n",
    "    table = soup.find(\"table\", {\"class\": \"team-roster\"})\n",
    "    \n",
    "    # Extract the header and data from the table\n",
    "    df = pd.read_html(table.prettify(), flavor='bs4')[0]\n",
    "    df[\"year\"] = year\n",
    "    team_name = soup.find(\"th\", {\"scope\": \"col\", \"class\": \"team-stat\"})\n",
    "    df[\"team_id\"] = team_id\n",
    "    \n",
    "    player_ids = {x.find('a').text: re.search(r'\\/([0-9]+)\\/index', x.find('a')['href']).group(1) for x in soup.find_all('td', {'class': 'player-name'}) if x.find('a', href=True)}\n",
    "    \n",
    "    df[\"player_id\"] = df[\"Name\"].apply(lambda x: player_ids.setdefault(x, None))\n",
    "    \n",
    "    df.columns = [x.lower().replace(' ', '_') for x in df.columns.tolist()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "ff8e50d5-bc22-4be1-a558-92e023a0f943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = f\"http://cfbstats.com/2020/team/{164}/index.html\"\n",
    "url = f\"http://cfbstats.com/2020/team/{721}/roster.html\"\n",
    "html_content = get_html_content(url)\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f684d460-199a-4144-a3c0-5befc0cab84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# player_names = {x.find('a').text: re.search(r'\\/([0-9]+)\\/index', x.find('a')['href']).group(1) for x in soup.find_all('td', {'class': 'player-name'}) if x.find('a', href=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "444f9b4b-c989-476a-844d-3c211477b92d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>name</th>\n",
       "      <th>pos</th>\n",
       "      <th>yr</th>\n",
       "      <th>ht</th>\n",
       "      <th>wt</th>\n",
       "      <th>hometown</th>\n",
       "      <th>last_school</th>\n",
       "      <th>year</th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Anderson, Matthew</td>\n",
       "      <td>DB</td>\n",
       "      <td>SR</td>\n",
       "      <td>6-2</td>\n",
       "      <td>195</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>Homestead</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>1106132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>Beasley, Britton</td>\n",
       "      <td>OL</td>\n",
       "      <td>SR</td>\n",
       "      <td>6-1</td>\n",
       "      <td>330</td>\n",
       "      <td>Cordell, OK</td>\n",
       "      <td>Cordell</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>Bein, Charles</td>\n",
       "      <td>P</td>\n",
       "      <td>FR</td>\n",
       "      <td>6-3</td>\n",
       "      <td>190</td>\n",
       "      <td>Mission Viejo, CA</td>\n",
       "      <td>San Clemente</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>1115598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Bentley, Brendan</td>\n",
       "      <td>LS</td>\n",
       "      <td>SO</td>\n",
       "      <td>6-2</td>\n",
       "      <td>250</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>Sierra Vista</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>1115611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>Blake, Kupono</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>1115616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>19</td>\n",
       "      <td>Wills II, Eric</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>1115606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9W</td>\n",
       "      <td>Wilson, Wyatt</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>62</td>\n",
       "      <td>Wimmer, Hawk</td>\n",
       "      <td>OG</td>\n",
       "      <td>JR</td>\n",
       "      <td>6-4</td>\n",
       "      <td>310</td>\n",
       "      <td>Franklin, WI</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>96</td>\n",
       "      <td>Woodring, Joey</td>\n",
       "      <td>NG</td>\n",
       "      <td>SR</td>\n",
       "      <td>5-11</td>\n",
       "      <td>275</td>\n",
       "      <td>Katy, TX</td>\n",
       "      <td>Katy</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>1097559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>23</td>\n",
       "      <td>Youngblood, Johnathan</td>\n",
       "      <td>FB</td>\n",
       "      <td>FR</td>\n",
       "      <td>5-11</td>\n",
       "      <td>220</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>E.L. Christian Academy</td>\n",
       "      <td>2022</td>\n",
       "      <td>721</td>\n",
       "      <td>1115591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    no                   name pos  yr    ht   wt           hometown   \n",
       "0   39      Anderson, Matthew  DB  SR   6-2  195     Fort Wayne, IN  \\\n",
       "1   56       Beasley, Britton  OL  SR   6-1  330        Cordell, OK   \n",
       "2   96          Bein, Charles   P  FR   6-3  190  Mission Viejo, CA   \n",
       "3   38       Bentley, Brendan  LS  SO   6-2  250      Las Vegas, NV   \n",
       "4   55          Blake, Kupono   -   -     -    -                  -   \n",
       "..  ..                    ...  ..  ..   ...  ...                ...   \n",
       "88  19         Wills II, Eric   -   -     -    -                  -   \n",
       "89  9W          Wilson, Wyatt   -   -     -    -                  -   \n",
       "90  62           Wimmer, Hawk  OG  JR   6-4  310       Franklin, WI   \n",
       "91  96         Woodring, Joey  NG  SR  5-11  275           Katy, TX   \n",
       "92  23  Youngblood, Johnathan  FB  FR  5-11  220        Atlanta, GA   \n",
       "\n",
       "               last_school  year  team_id player_id  \n",
       "0                Homestead  2022      721   1106132  \n",
       "1                  Cordell  2022      721      None  \n",
       "2             San Clemente  2022      721   1115598  \n",
       "3             Sierra Vista  2022      721   1115611  \n",
       "4                        -  2022      721   1115616  \n",
       "..                     ...   ...      ...       ...  \n",
       "88                       -  2022      721   1115606  \n",
       "89                       -  2022      721      None  \n",
       "90                Franklin  2022      721      None  \n",
       "91                    Katy  2022      721   1097559  \n",
       "92  E.L. Christian Academy  2022      721   1115591  \n",
       "\n",
       "[93 rows x 11 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = scrape_team_roster(soup, 2022, 721)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "eb41e2a5-0479-491c-a4e3-50180f033648",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Force 721\n",
      "[2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
      "Air Force\t2009\thttp://cfbstats.com/2009/team/721/index.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/131 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Scrape the team statistics for each desired year\n",
    "dataframes = []\n",
    "teams_dict = get_teams_dict()\n",
    "i = 0\n",
    "for team_name, team_id in tqdm(teams_dict.items()):\n",
    "    print(team_name, team_id)\n",
    "    years = get_years(team_id)\n",
    "    print(years)\n",
    "    for year in years:\n",
    "        url = f\"http://cfbstats.com/{year}/team/{team_id}/index.html\"\n",
    "        if year == years[0] or year == years[-1]:\n",
    "            print(f\"{team_name}\\t{year}\\t{url}\")\n",
    "        html_content = get_html_content(url)\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        break\n",
    "    break\n",
    "    #     df = scrape_team_schedule(soup, year)\n",
    "    #     dataframes.append(df)\n",
    "    # if i % 5 ==0:\n",
    "    #     pd.concat(dataframes, ignore_index=True).to_csv('cfb_stats_team_statistics.csv', index=False)\n",
    "    # i += 1\n",
    "# Combine the dataframes\n",
    "# pd.concat(dataframes, ignore_index=True).to_csv('cfb_stats_team_statistics.csv', index=False)\n",
    "# final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e44b2-10e3-4d6d-a6eb-b7c37df5e728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
